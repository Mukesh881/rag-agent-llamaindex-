# ğŸ¦™ Retrieval-Augmented Generation (RAG) Agent using LlamaIndex & Chroma

A modular, production-ready **Retrieval-Augmented Generation (RAG)** system built with [LlamaIndex](https://github.com/jerryjliu/llama_index), [Chroma](https://www.trychroma.com/), and both **OpenAI** and **Hugging Face** LLMs.

Upload PDFs, automatically build semantic indices, and query them in natural language â€” powered by dual embedding and inference pipelines for comparison, reliability, and flexibility.

---

## ğŸš€ Features

* ğŸ” **Dual embedding modes** â€” OpenAI (`text-embedding-3-small`) and HuggingFace (`BAAI/bge-small-en-v1.5`)
* âš™ï¸ **Persistent vector store** with Chroma â€” reuses embeddings if the PDF is unchanged
* ğŸ§  **Smart semantic chunking** â€” automatic text segmentation using `SemanticSplitterNodeParser`
* ğŸ’¬ **Dual LLM responses** â€” queries answered by both OpenAI (`gpt-3.5-turbo`) and HuggingFace Inference API (`Mixtral-8x7B-Instruct`)
* ğŸ§¾ **PDF-to-answer pipeline** â€” upload, embed, index, and chat â€” all in one command
* ğŸ§© **Evaluation support** â€” measures **Faithfulness**, **Relevancy**, and **Correctness** across engines
* ğŸ§ª **Fully testable** â€” includes offline-safe unit tests (no API calls)
* âš¡ **Smart caching** â€” detects PDF content changes via hashing and reindexes automatically

---

## ğŸ§° Tech Stack

| Category     | Library                                                |
| ------------ | ------------------------------------------------------ |
| Framework    | [LlamaIndex](https://github.com/jerryjliu/llama_index) |
| Vector Store | [ChromaDB](https://www.trychroma.com/)                 |
| Embeddings   | OpenAI, HuggingFace (BGE-small)                        |
| LLMs         | OpenAI GPT-3.5 Turbo, HuggingFace Mixtral 8x7B         |
| Evaluation   | LlamaIndex evaluators                                  |
| Config       | python-dotenv                                          |
| PDF Parsing  | pypdf                                                  |
| Testing      | pytest + mocks                                         |
| Utilities    | pandas, tqdm, nest_asyncio                             |

---

## ğŸ“ Project Structure

```
rag-agent-llamaindex/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                   # CLI entry point
â”‚   â”œâ”€â”€ config.py                # Logging and environment setup
â”‚   â”œâ”€â”€ loader.py                # PDF loader
â”‚   â”œâ”€â”€ embedding_indexer.py     # Node splitting & embedding index creation
â”‚   â”œâ”€â”€ rag_agent.py             # Dual query engine (OpenAI + HuggingFace)
â”‚   â””â”€â”€ evaluator.py             # Evaluation metrics & reporting
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_rag_agent.py        # Offline-safe test suite
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample.pdf               # Example document
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/<your-username>/rag-agent-llamaindex.git
cd rag-agent-llamaindex
```

### 2ï¸âƒ£ Create a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate      # macOS/Linux
.\.venv\Scripts\activate       # Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure your environment

Copy the example file and add your keys:

```bash
cp .env.example .env
```

Then fill it in:

```
OPENAI_API_KEY=sk-xxxx
HUGGINGFACE_API_KEY=hf_xxxx
```

If you donâ€™t have API keys, the agent automatically falls back to **local HuggingFace embeddings**, allowing full offline functionality.

---

## â–¶ï¸ Usage

### Query a PDF

```bash
python -m src.app --pdf ./data/sample.pdf --query "Summarize this document"
```

**Output:**

```
âœ… Existing vector indices found â€” skipping rebuild.

ğŸ§  OpenAI â†’ The document describes LICâ€™s New Jeevan Shanti policy with guaranteed annuity.
ğŸ¤— HuggingFace â†’ This PDF outlines the annuity options and eligibility criteria under the plan.
```

### Evaluate performance

```bash
python -m src.app --pdf ./data/sample.pdf --run-eval
```

Example summary:

```
ğŸ“Š EVALUATION RESULTS SUMMARY
----------------------------------------
ğŸ§  OpenAI-based Index:
Faithfulness    : 88.0%
Relevancy       : 90.5%
Correctness     : 85.0%

ğŸ¤— HuggingFace-based Index:
Faithfulness    : 83.0%
Relevancy       : 88.0%
Correctness     : 81.0%
```

---

## ğŸ§© Offline Mode

No API keys? No problem.

When `OPENAI_API_KEY` isnâ€™t set, the system automatically:

* Uses **BAAI/bge-small-en-v1.5** local embedding model
* Skips OpenAI calls entirely
* Runs queries fully offline

This makes development and testing seamless.

---

## ğŸ§ª Testing

Run all tests:

```bash
pytest -v
```

Run only local tests:

```bash
pytest -v -k "split or index"
```

Run integration (live API) tests:

```bash
pytest -v --runlive
```

Offline tests create valid PDFs using `reportlab` and verify the full pipeline without hitting external APIs.

---

## ğŸ§± Example Dual Query Output

| Engine                                  | Response                                                                       |
| --------------------------------------- | ------------------------------------------------------------------------------ |
| **OpenAI GPT-3.5 Turbo**                | â€œThe document describes an annuity plan under LICâ€™s New Jeevan Shanti policy.â€ |
| **HuggingFace Mixtral (Inference API)** | â€œThis PDF outlines LICâ€™s guaranteed pension product and key benefits.â€         |

---

## ğŸ“Š Evaluation Metrics Explained

| Metric           | Meaning                                                |
| ---------------- | ------------------------------------------------------ |
| **Faithfulness** | Does the modelâ€™s answer align with the document facts? |
| **Relevancy**    | Is the answer focused on the question context?         |
| **Correctness**  | Does the model respond accurately and completely?      |

All evaluated using GPT-based evaluators via LlamaIndex.

---

## ğŸ§  Design Philosophy

This project follows **modular AI system design** principles:

* Clear separation between loading, embedding, retrieval, and generation.
* Environment-agnostic (works both with and without API keys).
* Fully reproducible pipeline for RAG benchmarking.
* Practical and inspectable code for AI engineers learning LlamaIndex.

---

## ğŸ§¹ Maintenance

| Command            | Purpose                  |
| ------------------ | ------------------------ |
| `black .`          | Auto-format code         |
| `flake8`           | Lint for PEP8 compliance |
| `pytest -v`        | Run all tests            |
| `pytest --cov=src` | Generate coverage report |
| `deactivate`       | Exit virtual environment |

---

## ğŸ§¾ License

This project is released under the [MIT License](LICENSE).

---

## ğŸ’¡ Next Steps

* [ ] Add Streamlit UI for drag-and-drop PDF querying
* [ ] Integrate FAISS / Milvus for scalable multi-PDF retrieval
* [ ] Add caching layer (LangChain retriever or SQLite)
* [ ] Serve via FastAPI for production inference

